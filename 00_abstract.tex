\begin{abstract}
Comparing approaches in the area of streaming anomaly detection can be challenging, as the descriptive research output is often not equally complete, not similarly structured, or not evaluated coherently and on similar data. This work introduces a set of foundational features that can be used to categorize, evaluate, and compare anomaly detection approaches in the streaming context, and should aid in doing so more fairly. Some of the proposed features describe capabilities that are essential in real-world application, while others help judge the quality and completeness of the performed evaluation. We introduce some existing research for each of the different categories and align that research according to our proposed features. Finally, we provide some intuition on open challenges that can hinder the real-world applicability of approaches.
\end{abstract}